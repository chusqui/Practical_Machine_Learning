---
title: "prediction"
author: "Jesus Escribano"
date: "Friday, October 24, 2014"
output: html_document
---

# Personal Activity Prediction From Machine Learning Techniques
===============================================================

## Executive Summary
The goal of this exercise is to use the reading from several sensory data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants, and to predict the outcome of the manner in which they did the exercise. This outcome is denoted by classe variable in the dataset. These participants were further asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).
We have surveyed different machine learning techniques and concluded that Random Forest was the best model for predicting the manner in which the participants did the exercise.

## Data Loading

We download the dataset  and then read the files.

```{r,results='hide',cache=TRUE}
setwd("d:\\")
library(caret)
```

```{r}
# read training dataset for pre-processing
training <- read.csv("d:\\training.csv", na.strings=c("", "NA", "NULL"))
# read testing dataset for pre-processing
testing <- read.csv("d:\\testing.csv", na.strings=c("", "NA", "NULL"))
# remove columns from training set that consist mostly of NAs and blanks
```

## Feature Selection and Preprocessing
We removed variables that we think that are not related with the variable classe and that have lots of NAs and blanks.


- Remove variables that we believe have too many NA values.

```{r}
training.1 <- training[ , colSums(is.na(training)) == 0]
#head(training1)
#training3 <- training.decor[ rowSums(is.na(training.decor)) == 0, ]
dim(training.1)

```

- Remove unrelevant variables
There are some unrelevant variables that can be removed as they are unlikely to be related to dependent variable.

```{r}
remove = c('X', 'user_name', 'raw_timestamp_part_1', 'raw_timestamp_part_2', 'cvtd_timestamp', 'new_window', 'num_window')
training.2 <- training.1[, -which(names(training.1) %in% remove)]
dim(training.2)
```


- Check the variables that have extremely low variance (this method is useful nearZeroVar() )

```{r}

# only numeric variabls can be evaluated in this way.

zeroVar= nearZeroVar(training.2[sapply(training.2, is.numeric)], saveMetrics = TRUE)
training.3 = training.2[,zeroVar[, 'nzv']==0]
dim(training.3)

```

- Remove highly correlated variables 90% (using for example findCorrelation() )

```{r}
# only numeric variabls can be evaluated in this way.
corrMatrix <- cor(na.omit(training.3[sapply(training.3, is.numeric)]))
dim(corrMatrix)
# there are 52 variables.
corrDF <- expand.grid(row = 1:52, col = 1:52)
corrDF$correlation <- as.vector(corrMatrix)
levelplot(correlation ~ row+ col, corrDF)


```

We are going to remove those variable which have high correlation.


```{r ,results='hide'}
removecor = findCorrelation(corrMatrix, cutoff = .90, verbose = TRUE)
```



```{r}
training = training.3[,-removecor]
dim(training)
```

With the original training data, we create two new data sets, one to train the model (using 70% of the original data), and a second to test this model (with the rest 30%).

```{r}
set.seed(1)
library(caret)
inTrain <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)
training <- training[inTrain, ]  
validation <- training[-inTrain, ]     
```

The  final dataset for training has 13737 obs. of  46  variables. It contains the data from variables  we can use it to build the  prediction model an then predict using the testing dataset.
```{r}
str(training)
```

## Predictive Modelling 
Now we will train the model with a series of predictive modelling tools:
1. Tree based modelling
2. Random Forest 
and analyze the performance of these models 

### Tree based modelling
A tree-based prediction method (e.g. CART) partitions the feature (variables) space into a set of rectangles, on which fixed constants (predictions) are assigned. We can use the rpart function in the rpart package, which implements CART. We also use prp to plot rplot trees with better rendering options.

```{r,  fig.width = 18, fig.height = 10, , message=F, warning=F}
library(rpart)
library(rpart.plot)
p1 <- rpart(classe ~ ., data = training)
prp(p1, extra=6, box.col=c("pink", "palegreen3")[p1$frame$yval])
```


### Random Forest
Random Forest injects additional randomness into the bagging procedure on trees: each node is split using the best among a subset of predictors randomly chosen at that node, instead of the full set. This prediction model usually provides superior performance and is robust against overfitting by keeping healthy SNR (signal to noise ratio). We make use of CRAN's randomForest library to use this prediction, and the plot method traces the error rates (out-of-bag, and by each response category) as the number of trees increases.

```{r,cache=TRUE, fig.width = 18, fig.height = 10, , message=F, warning=F}
require(randomForest)

set.seed(12345)

p2 <- randomForest(classe~. , data=training , ntree=100, importance=TRUE)

```

The importance option in the randomForest function requests the assessment of predictor importances. This plot shows measure in the mean descrease in accuracy over all classes:

```{r,cache=TRUE,  message=F, warning=F}
 varImpPlot(p2,)
```


## Testing Prediction Models
The prediction  on the validation dataset for Tree and  Random Forest is:

```{r,cache=TRUE}
output<-data.frame(Truth = validation$classe, Tree = predict(p1, validation, type = "class"),  Forest = predict(p2, validation,type="class") ) 

sum(output$Truth==output$Tree); 
sum(output$Truth==output$Forest)
```
 As we can see RandomForest algorithm seemed to have done much better of predicting 4112 out of 5885 variables correctly among the other  algorithm. 

## Conclusion

We conclude that the RandomForest is the best prediction model for our dataset. The error estimation obtained by RandomForest is conclusively lower than that of the other model we have surveyed.

Applying our final prediction model applied to our final testing dataset.

```{r}
library(randomForest)
answers <- predict(p2, testing)
summary(answers)
```

Here is the submission file that we need to generate in order to complete the second part of this project.
```{r submit,eval=FALSE}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(answers)
```
